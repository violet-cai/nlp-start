{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-25T08:41:35.980643Z",
     "start_time": "2024-10-25T08:41:33.728085Z"
    }
   },
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "model = \"./models/hfl/chinese-macbert-base\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "nlp = pipeline(\"fill-mask\",\n",
    "               model=model,\n",
    "               tokenizer=model,\n",
    "               device=device  # gpu device id\n",
    "               )\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(nlp(f\"明天天{nlp.tokenizer.mask_token}很好?\"))\n",
    "print(\"*\" * 42)\n",
    "pprint(nlp(f\"明天心{nlp.tokenizer.mask_token}很好?\"))\n",
    "print(\"*\" * 42)\n",
    "pprint(nlp(f\"张亮在哪里任{nlp.tokenizer.mask_token}?\"))\n",
    "print(\"*\" * 42)\n",
    "pprint(nlp(f\"少先队员{nlp.tokenizer.mask_token}该为老人让座位。\"))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./models/hfl/chinese-macbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.30065131187438965,\n",
      "  'sequence': '明 天 天 气 很 好?',\n",
      "  'token': 3698,\n",
      "  'token_str': '气'},\n",
      " {'score': 0.10563581436872482,\n",
      "  'sequence': '明 天 天 会 很 好?',\n",
      "  'token': 833,\n",
      "  'token_str': '会'},\n",
      " {'score': 0.09691523760557175,\n",
      "  'sequence': '明 天 天 还 很 好?',\n",
      "  'token': 6820,\n",
      "  'token_str': '还'},\n",
      " {'score': 0.08303287625312805,\n",
      "  'sequence': '明 天 天 就 很 好?',\n",
      "  'token': 2218,\n",
      "  'token_str': '就'},\n",
      " {'score': 0.08257950097322464,\n",
      "  'sequence': '明 天 天 都 很 好?',\n",
      "  'token': 6963,\n",
      "  'token_str': '都'}]\n",
      "******************************************\n",
      "[{'score': 0.6035325527191162,\n",
      "  'sequence': '明 天 心 情 很 好?',\n",
      "  'token': 2658,\n",
      "  'token_str': '情'},\n",
      " {'score': 0.20563046634197235,\n",
      "  'sequence': '明 天 心 会 很 好?',\n",
      "  'token': 833,\n",
      "  'token_str': '会'},\n",
      " {'score': 0.05586212873458862,\n",
      "  'sequence': '明 天 心 也 很 好?',\n",
      "  'token': 738,\n",
      "  'token_str': '也'},\n",
      " {'score': 0.026620039716362953,\n",
      "  'sequence': '明 天 心 就 很 好?',\n",
      "  'token': 2218,\n",
      "  'token_str': '就'},\n",
      " {'score': 0.015123298391699791,\n",
      "  'sequence': '明 天 心 态 很 好?',\n",
      "  'token': 2578,\n",
      "  'token_str': '态'}]\n",
      "******************************************\n",
      "[{'score': 0.18465301394462585,\n",
      "  'sequence': '张 亮 在 哪 里 任 啊?',\n",
      "  'token': 1557,\n",
      "  'token_str': '啊'},\n",
      " {'score': 0.17146055400371552,\n",
      "  'sequence': '张 亮 在 哪 里 任 的?',\n",
      "  'token': 4638,\n",
      "  'token_str': '的'},\n",
      " {'score': 0.09111890941858292,\n",
      "  'sequence': '张 亮 在 哪 里 任??',\n",
      "  'token': 136,\n",
      "  'token_str': '?'},\n",
      " {'score': 0.0695233941078186,\n",
      "  'sequence': '张 亮 在 哪 里 任 职?',\n",
      "  'token': 5466,\n",
      "  'token_str': '职'},\n",
      " {'score': 0.06648154556751251,\n",
      "  'sequence': '张 亮 在 哪 里 任 过?',\n",
      "  'token': 6814,\n",
      "  'token_str': '过'}]\n",
      "******************************************\n",
      "[{'score': 0.2678063213825226,\n",
      "  'sequence': '少 先 队 员 也 该 为 老 人 让 座 位 。',\n",
      "  'token': 738,\n",
      "  'token_str': '也'},\n",
      " {'score': 0.252871036529541,\n",
      "  'sequence': '少 先 队 员 不 该 为 老 人 让 座 位 。',\n",
      "  'token': 679,\n",
      "  'token_str': '不'},\n",
      " {'score': 0.17268414795398712,\n",
      "  'sequence': '少 先 队 员 应 该 为 老 人 让 座 位 。',\n",
      "  'token': 2418,\n",
      "  'token_str': '应'},\n",
      " {'score': 0.08332759886980057,\n",
      "  'sequence': '少 先 队 员 都 该 为 老 人 让 座 位 。',\n",
      "  'token': 6963,\n",
      "  'token_str': '都'},\n",
      " {'score': 0.05233199521899223,\n",
      "  'sequence': '少 先 队 员 ， 该 为 老 人 让 座 位 。',\n",
      "  'token': 8024,\n",
      "  'token_str': '，'}]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T08:41:37.820045Z",
     "start_time": "2024-10-25T08:41:35.997951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "model = AutoModelWithLMHead.from_pretrained(model)\n",
    "\n",
    "sequence = f\"明天心{nlp.tokenizer.mask_token}很好.\"\n",
    "input = tokenizer.encode(sequence, return_tensors=\"pt\")\n",
    "mask_token_index = torch.where(input == tokenizer.mask_token_id)[1]\n",
    "token_logits = model(input).logits\n",
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n",
    "for token in top_5_tokens:\n",
    "    print(sequence.replace(tokenizer.mask_token, tokenizer.decode([token])))"
   ],
   "id": "653629cdbda6d86c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./models/hfl/chinese-macbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "明天心会很好.\n",
      "明天心情很好.\n",
      "明天心也很好.\n",
      "明天心就很好.\n",
      "明天心还很好.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "657ca58dae6ea0a5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
