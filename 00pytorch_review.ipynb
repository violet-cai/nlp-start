{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T07:55:00.219936Z",
     "start_time": "2024-10-31T07:55:00.216505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ],
   "id": "7a6ef9f9702b211c",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T07:55:00.281307Z",
     "start_time": "2024-10-31T07:55:00.274228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def my_cross_entropy(x, y):\n",
    "    loss = []\n",
    "    for i, cls in enumerate(y):\n",
    "        x_class = -x[i][cls]\n",
    "        log_x_j = np.log(sum([np.exp(j) for j in x[i]]))\n",
    "        loss.append(x_class + log_x_j)\n",
    "    return np.mean(loss)\n",
    "\n",
    "\n",
    "x = np.array([\n",
    "    [0.1545, -0.5706, -0.0739],\n",
    "    [0.2990, 0.1373, 0.0784],\n",
    "    [0.1633, 0.0226, 0.8038]\n",
    "])\n",
    "\n",
    "# 分类标签\n",
    "y = np.array([0, 1, 2])\n",
    "\n",
    "print(\"my CrossEntropyLoss output: %.4f\" % my_cross_entropy(x, y))\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "x_tensor = torch.from_numpy(x)\n",
    "y_tensor = torch.from_numpy(y)\n",
    "output = loss(x_tensor, y_tensor)\n",
    "print(\"torch CrossEntropyLoss output: %.4f\" % output)"
   ],
   "id": "1606a35f11084cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my CrossEntropyLoss output: 0.8824\n",
      "torch CrossEntropyLoss output: 0.8824\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T07:55:00.409158Z",
     "start_time": "2024-10-31T07:55:00.404525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def my_MSE(x, y):\n",
    "    loss = []\n",
    "    for i, j in zip(x, y):\n",
    "        loss.append((i - j) ** 2)\n",
    "    return np.mean(loss)\n",
    "\n",
    "\n",
    "x = np.array([1., 2, 10])\n",
    "y = np.array([0, 1, 2])\n",
    "print(\"my CrossEntropyLoss output: %.4f\" % my_MSE(x, y))\n",
    "loss = torch.nn.MSELoss()\n",
    "x_tensor = torch.from_numpy(x)\n",
    "y_tensor = torch.from_numpy(y)\n",
    "output = loss(x_tensor, y_tensor)\n",
    "print(\"torch CrossEntropyLoss output: %.4f\" % output)"
   ],
   "id": "ffd29e28102e7ae8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my CrossEntropyLoss output: 22.0000\n",
      "torch CrossEntropyLoss output: 22.0000\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T07:55:00.463707Z",
     "start_time": "2024-10-31T07:55:00.460716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    # t 表示 target，y 是预测值\n",
    "    delta = 1e-7  #添加一个微小值可以防止负无限大(np.log(0))的发生。\n",
    "    return -np.sum(t * np.log(y + delta))"
   ],
   "id": "377b294a1d8323a6",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T07:55:00.511517Z",
     "start_time": "2024-10-31T07:55:00.508654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def mse_error(y, t):\n",
    "    # t 表示 target，y 是预测值，就是\n",
    "    return 1.0 / 2 * (y - t) ** 2"
   ],
   "id": "967756e6eee57a7c",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T07:55:00.571623Z",
     "start_time": "2024-10-31T07:55:00.568447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.x = torch.randn(1)\n",
    "        self.register_buffer('y', torch.randn(1))  # 不会更新\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.x"
   ],
   "id": "c214cc4bd2470cf4",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T07:55:00.630673Z",
     "start_time": "2024-10-31T07:55:00.619342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import Tensor\n",
    "from typing import Optional, Dict, Tuple\n",
    "\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    \"\"\"Multi-headed attention from 'Attention Is All You Need' paper\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            embed_dim,\n",
    "            num_heads,\n",
    "            dropout=0.0,\n",
    "            bias=True,\n",
    "            encoder_decoder_attention=False,  # otherwise self_attention\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "        assert self.head_dim * num_heads == self.embed_dim, \"embed_dim must be divisible by num_heads\"\n",
    "        self.scaling = self.head_dim ** -0.5\n",
    "\n",
    "        self.encoder_decoder_attention = encoder_decoder_attention\n",
    "        self.k_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
    "        self.v_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
    "        self.q_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
    "        self.out_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
    "        self.cache_key = \"encoder_decoder\" if self.encoder_decoder_attention else \"self\"\n",
    "\n",
    "    def _shape(self, tensor, seq_len, bsz):\n",
    "        return tensor.contiguous().view(seq_len, bsz * self.num_heads, self.head_dim).transpose(0, 1)\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            query,\n",
    "            key: Optional[Tensor],\n",
    "            key_padding_mask: Optional[Tensor] = None,\n",
    "            layer_state: Optional[Dict[str, Optional[Tensor]]] = None,\n",
    "            attn_mask: Optional[Tensor] = None,\n",
    "            output_attentions=False,\n",
    "    ) -> Tuple[Tensor, Optional[Tensor]]:\n",
    "        \"\"\"Input shape: Time(SeqLen) x Batch x Channel\"\"\"\n",
    "        static_kv: bool = self.encoder_decoder_attention\n",
    "        tgt_len, bsz, embed_dim = query.size()\n",
    "        assert embed_dim == self.embed_dim\n",
    "        assert list(query.size()) == [tgt_len, bsz, embed_dim]\n",
    "        # get here for encoder decoder cause of static_kv\n",
    "        if layer_state is not None:  # reuse k,v and encoder_padding_mask\n",
    "            saved_state = layer_state.get(self.cache_key, {})\n",
    "            if \"prev_key\" in saved_state and static_kv:\n",
    "                # previous time steps are cached - no need to recompute key and value if they are static\n",
    "                key = None\n",
    "        else:\n",
    "            saved_state = None\n",
    "            layer_state = {}\n",
    "\n",
    "        q = self.q_proj(query) * self.scaling\n",
    "        if static_kv:\n",
    "            if key is None:\n",
    "                k = v = None\n",
    "            else:\n",
    "                k = self.k_proj(key)\n",
    "                v = self.v_proj(key)\n",
    "        else:\n",
    "            k = self.k_proj(query)\n",
    "            v = self.v_proj(query)\n",
    "\n",
    "        q = self._shape(q, tgt_len, bsz)\n",
    "        if k is not None:\n",
    "            k = self._shape(k, -1, bsz)\n",
    "        if v is not None:\n",
    "            v = self._shape(v, -1, bsz)\n",
    "\n",
    "        if saved_state is not None:\n",
    "            k, v, key_padding_mask = self._use_saved_state(k, v, saved_state, key_padding_mask, static_kv, bsz)\n",
    "\n",
    "        assert k is not None\n",
    "        src_len = k.size(1)\n",
    "        attn_weights = torch.bmm(q, k.transpose(1, 2))\n",
    "        assert attn_weights.size() == (bsz * self.num_heads, tgt_len, src_len)\n",
    "\n",
    "        if attn_mask is not None:\n",
    "            attn_weights = attn_weights.view(bsz, self.num_heads, tgt_len, src_len) + attn_mask\n",
    "            attn_weights = attn_weights.view(bsz * self.num_heads, tgt_len, src_len)\n",
    "\n",
    "        # This is part of a workaround to get around fork/join parallelism not supporting Optional types.\n",
    "        if key_padding_mask is not None and key_padding_mask.dim() == 0:\n",
    "            key_padding_mask = None\n",
    "        assert key_padding_mask is None or key_padding_mask.size()[:2] == (bsz, src_len,)\n",
    "\n",
    "        if key_padding_mask is not None:  # don't attend to padding symbols\n",
    "            attn_weights = attn_weights.view(bsz, self.num_heads, tgt_len, src_len)\n",
    "            reshaped = key_padding_mask.unsqueeze(1).unsqueeze(2)\n",
    "            attn_weights = attn_weights.masked_fill(reshaped, float(\"-inf\"))\n",
    "            attn_weights = attn_weights.view(bsz * self.num_heads, tgt_len, src_len)\n",
    "        attn_weights = F.softmax(attn_weights, dim=-1)\n",
    "        attn_probs = F.dropout(attn_weights, p=self.dropout, training=self.training, )\n",
    "\n",
    "        assert v is not None\n",
    "        attn_output = torch.bmm(attn_probs, v)\n",
    "        assert attn_output.size() == (bsz * self.num_heads, tgt_len, self.head_dim)\n",
    "        attn_output = attn_output.transpose(0, 1).contiguous().view(tgt_len, bsz, embed_dim)\n",
    "        attn_output = self.out_proj(attn_output)\n",
    "        if output_attentions:\n",
    "            attn_weights = attn_weights.view(bsz, self.num_heads, tgt_len, src_len)\n",
    "        else:\n",
    "            attn_weights = None\n",
    "        return attn_output, attn_weights\n",
    "\n",
    "    def _use_saved_state(self, k, v, saved_state, key_padding_mask, static_kv, bsz):\n",
    "        # saved states are stored with shape (bsz, num_heads, seq_len, head_dim)\n",
    "        if \"prev_key\" in saved_state:\n",
    "            _prev_key = saved_state[\"prev_key\"]\n",
    "            assert _prev_key is not None\n",
    "            prev_key = _prev_key.view(bsz * self.num_heads, -1, self.head_dim)\n",
    "            if static_kv:\n",
    "                k = prev_key\n",
    "            else:\n",
    "                assert k is not None\n",
    "                k = torch.cat([prev_key, k], dim=1)\n",
    "        if \"prev_value\" in saved_state:\n",
    "            _prev_value = saved_state[\"prev_value\"]\n",
    "            assert _prev_value is not None\n",
    "            prev_value = _prev_value.view(bsz * self.num_heads, -1, self.head_dim)\n",
    "            if static_kv:\n",
    "                v = prev_value\n",
    "            else:\n",
    "                assert v is not None\n",
    "                v = torch.cat([prev_value, v], dim=1)\n",
    "        assert k is not None and v is not None\n",
    "        prev_key_padding_mask: Optional[Tensor] = saved_state.get(\"prev_key_padding_mask\", None)\n",
    "        if prev_key_padding_mask is not None:\n",
    "            if static_kv:\n",
    "                new_key_padding_mask = prev_key_padding_mask\n",
    "            else:\n",
    "                new_key_padding_mask = torch.cat([prev_key_padding_mask, key_padding_mask], dim=1)\n",
    "        else:\n",
    "            new_key_padding_mask = key_padding_mask\n",
    "        return k, v, new_key_padding_mask"
   ],
   "id": "9c096d0d311a6036",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3c8999a02d78a33d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
